{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Scope+ User Tutorial This tutorial is made for Scope+ and is straightforward. You only need three separate files to start implement your own single-cell atlas portal using the Scope+ architecture. Input file Metadata Count matrix UMAP coordinates Example input files are provided for your reference. Input files needed to be in .csv format. We assume that users have analyzed their data in one of the most popular software Seurat in R. You can output your three input files from your Seurat object by: Metadata: your own metadata file in .csv format i.e. meta.csv Count matrix: # convert the sparse count matrix into dense matrix # https://stackoverflow.com/questions/4558277/write-a-sparse-matrix-to-a-csv-in-r sparse2triples <- function(m) { SM = summary(m) D1 = m@Dimnames[[1]][SM[,1]] D2 = m@Dimnames[[2]][SM[,2]] data.frame(row=D1, col=D2, x=m@x) } # get matrix file dense_matrix <- sparse2triples(srt_obj[[\"RNA\"]]@counts) colnames(dense_matrix) <- c(\"gene_name\", \"barcode\",\"expression\") write.csv(dense_matrix, file=\"matrix.csv\", row.names=FALSE) For large-scale single-cell data we also provide utilities to convert the 10X single-cell RNA-seq data to MongoDB import collection .csv format at here . UMAP: If you have run the UMAP step, otherwise please refer to Seurat UMAP method and run it first. umap_coord <- dplyr::as_tibble(data.frame(seurat_object@reductions$umap@cell.embeddings), rownames = \"id\") colnames(umap_coord) <- c(\u201did\u201c, \u201cUMAP1\u201d,\u201dUMAP2\u201d) write.csv(umap_coord, file=\u201dumap.csv\u201d, row.names=FALSE) Input file format **File name** **Collection name** **Columns** metadata.csv single_cell_meta_v4 [\"id\", \"meta_age_category\", \"meta_sample_id2\",\"meta_patient_id\", \"meta_dataset\", \"level2\", \"meta_severity\", \"meta_days_from_onset_of_symptoms\", \"meta_outcome\", \"meta_gender\", \"Country\"] matrix.csv matrix [\"barcode\", \"gene_name\",\"expression\"] umap.csv umap [\"UMAP1\",\"UMAP2\", \"id\"] Database collection **Column name** **Value format** **Description** **Example** Collection schema: **single_cell_meta_v4** id String Cell barcode (unique) meta_patient_id String Patient identifier meta_sample_id2 String Sample identifier (one patient may have multiple samples) Country String Country origin of the dataset meta_age_category String Age category in intervals e.g. \u201c18-30\u201d level2 String Cell type predictions meta_severity String The severity of the symptoms regarding patient meta_dataset String Dataset origin meta_days_from_onset_of_symptoms Number Days from the onset of symptoms meta_gender String Gender i.e. \u201cfemale\u201d or \u201cmale\u201d meta_outcome String Health outcome i.e. \u201cdiseased\u201d, \u201cdischarged\u201d etc. Collection schema: **umap** id String Cell barcode (unique) UMAP1 String X-coordinate of the cell UMAP2 String Y-coordiante of the cell Collection schema: **matrix** barcode String Cell barcode (unique) gene_name String Name of the gene expressed in the cell e.g. CD19 expression Number Dependencies MongoDB installed Python3.9 installed MongoDB Compass installed (optional, for visual operation of the database) sqlite installed Reimplementation one-by-one steps Install the system dependencies listed above, MongoDB, Python, MongoDB Compass (optional) and sqlite. Create a database in MongoDB named cov19atlas_new, and create three collections namely under the database single_cell_meta_v4 umap matrix Import the three datasets into MongoDB using MongoDB Compass, make sure all data field during import needs to be in STRING format.: single_cell_meta_v4 ( importdata_meta.csv ) umap ( importdata_umap.csv ) and matrix ( importdata_matrix.csv ). Download Covidscope web portal resources below into flask_resources directory under your $HOME, without them the web portal can't be initialized features.tsv db.sqlite Clone the repository, install the packages for Covidscope and run the web portal code Quickstart guide (after data imported to MongoDB) $ git clone https://github.com/hiyin/covid19_cell_atlas_portal.git $ cd covid19_cell_atlas_portal # create virtual environment $ python3.9 -m pip install --upgrade pip $ python3.9 -m venv venv # this installs the venv folder in the current directory $ source venv/bin/activate $ pip install -r requirements.txt # deactivate the environment and reactivate it for a fresh start $ deactivate $ source venv/bin/activate # initialize database download it and put it in flask_resources/ directory in yor $HOME mv db.sqlite $HOME/flask_resources/ mv features.tsv $HOME/flask_resources/ # set environment $ export FLASK_ENV=development $ export FLASK_APP=manage.py # launch $ flask run You will have local version of Covidscope running at 127.0.0.1:5000 by default. You shall be able to have your own version of Covidscope running with your custom files if you could modify to the data format same as the example files we used here for demonstration! Prepare your data for Scope+ reimplementation We assume that you start with the two common files after you have collected your single-cell RNA-seq data i.e. meta data, and a count matrix folder in 10X single-cell sequencing format. Below is a example pipeline to help you to process the files. We asssume that you have a metadata file following our structures (if not please edit according to our example metadata) Example metadata: metadata Example 10X format matrix folder files: barcodes.tsv.gz genes.tsv.gz matrix.mtx.gz Download them and save as into a new directory named hoehn_2021/ meta <- read.csv(\"importdata_metadata.csv\") # Prepare matrix db collection source hoehn <- Read10X(\"hoehn_2021/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(hoehn) rownames(meta) <- meta$id metadata_frame <- srt_obj@meta.data univ_meta <- cbind(metadata_frame, meta) srt_obj <- AddMetaData(srt_obj, univ_meta) # if the user didn't have pca srt_obj <- NormalizeData(srt_obj) srt_obj <- FindVariableFeatures(srt_obj, selection.method = \"vst\", nfeatures = 2000) all.genes <- rownames(srt_obj) srt_obj <- ScaleData(srt_obj, features=all.genes) srt_obj <- RunPCA(srt_obj, features = VariableFeatures(object = srt_obj)) srt_obj <- RunUMAP(srt_obj, dims = 1:40) # Prepare UMAP file for database import umap_coord <- dplyr::as_tibble(data.frame(srt_obj@reductions$umap@cell.embeddings ), rownames = \"id\") colnames(umap_coord) <- c(\"id\", \"UMAP1\",\"UMAP2\") write.csv(umap_coord, file=\"importdata_umap.csv\", row.names = FALSE) # Prepare matrix file for database import # input: a sparse matrix with named rows and columns (dimnames) # returns: a data frame representing triplets (r, c, x) suitable for writing to a CSV file sparse2triples <- function(m) { SM = summary(m) D1 = m@Dimnames[[1]][SM[,1]] D2 = m@Dimnames[[2]][SM[,2]] data.frame(row=D1, col=D2, x=m@x) } # get matrix file towrite_matrix <- sparse2triples(srt_obj[[\"RNA\"]]@counts) colnames(towrite_matrix) <- c(\"gene_name\", \"barcode\", \"expression\") # write matrix data write.csv(towrite_matrix, file=\"importdata_matrix.csv\", row.names=FALSE) For a quick reproduction of Covidscope local version, you could download our prepared and processed files and directly import them into the MongoDB: 1. matrix 2. metadata 3. umap How to use Covidscope data For any user would like to use Covidscope data, downloaded from https://covidsc.d24h.hk/data, Covidscope provide the data in 10X format therefore you can read the three .gz files using Seurat package's function Read10X . An example is given below data <- Read10X(\"lee_2020/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(data)","title":"Scope+ User Tutorial"},{"location":"#scope-user-tutorial","text":"This tutorial is made for Scope+ and is straightforward. You only need three separate files to start implement your own single-cell atlas portal using the Scope+ architecture.","title":"Scope+ User Tutorial"},{"location":"#input-file","text":"Metadata Count matrix UMAP coordinates Example input files are provided for your reference. Input files needed to be in .csv format. We assume that users have analyzed their data in one of the most popular software Seurat in R. You can output your three input files from your Seurat object by: Metadata: your own metadata file in .csv format i.e. meta.csv Count matrix: # convert the sparse count matrix into dense matrix # https://stackoverflow.com/questions/4558277/write-a-sparse-matrix-to-a-csv-in-r sparse2triples <- function(m) { SM = summary(m) D1 = m@Dimnames[[1]][SM[,1]] D2 = m@Dimnames[[2]][SM[,2]] data.frame(row=D1, col=D2, x=m@x) } # get matrix file dense_matrix <- sparse2triples(srt_obj[[\"RNA\"]]@counts) colnames(dense_matrix) <- c(\"gene_name\", \"barcode\",\"expression\") write.csv(dense_matrix, file=\"matrix.csv\", row.names=FALSE) For large-scale single-cell data we also provide utilities to convert the 10X single-cell RNA-seq data to MongoDB import collection .csv format at here . UMAP: If you have run the UMAP step, otherwise please refer to Seurat UMAP method and run it first. umap_coord <- dplyr::as_tibble(data.frame(seurat_object@reductions$umap@cell.embeddings), rownames = \"id\") colnames(umap_coord) <- c(\u201did\u201c, \u201cUMAP1\u201d,\u201dUMAP2\u201d) write.csv(umap_coord, file=\u201dumap.csv\u201d, row.names=FALSE)","title":"Input file"},{"location":"#input-file-format","text":"**File name** **Collection name** **Columns** metadata.csv single_cell_meta_v4 [\"id\", \"meta_age_category\", \"meta_sample_id2\",\"meta_patient_id\", \"meta_dataset\", \"level2\", \"meta_severity\", \"meta_days_from_onset_of_symptoms\", \"meta_outcome\", \"meta_gender\", \"Country\"] matrix.csv matrix [\"barcode\", \"gene_name\",\"expression\"] umap.csv umap [\"UMAP1\",\"UMAP2\", \"id\"]","title":"Input file format"},{"location":"#database-collection","text":"**Column name** **Value format** **Description** **Example** Collection schema: **single_cell_meta_v4** id String Cell barcode (unique) meta_patient_id String Patient identifier meta_sample_id2 String Sample identifier (one patient may have multiple samples) Country String Country origin of the dataset meta_age_category String Age category in intervals e.g. \u201c18-30\u201d level2 String Cell type predictions meta_severity String The severity of the symptoms regarding patient meta_dataset String Dataset origin meta_days_from_onset_of_symptoms Number Days from the onset of symptoms meta_gender String Gender i.e. \u201cfemale\u201d or \u201cmale\u201d meta_outcome String Health outcome i.e. \u201cdiseased\u201d, \u201cdischarged\u201d etc. Collection schema: **umap** id String Cell barcode (unique) UMAP1 String X-coordinate of the cell UMAP2 String Y-coordiante of the cell Collection schema: **matrix** barcode String Cell barcode (unique) gene_name String Name of the gene expressed in the cell e.g. CD19 expression Number","title":"Database collection"},{"location":"#dependencies","text":"MongoDB installed Python3.9 installed MongoDB Compass installed (optional, for visual operation of the database) sqlite installed","title":"Dependencies"},{"location":"#reimplementation-one-by-one-steps","text":"Install the system dependencies listed above, MongoDB, Python, MongoDB Compass (optional) and sqlite. Create a database in MongoDB named cov19atlas_new, and create three collections namely under the database single_cell_meta_v4 umap matrix Import the three datasets into MongoDB using MongoDB Compass, make sure all data field during import needs to be in STRING format.: single_cell_meta_v4 ( importdata_meta.csv ) umap ( importdata_umap.csv ) and matrix ( importdata_matrix.csv ). Download Covidscope web portal resources below into flask_resources directory under your $HOME, without them the web portal can't be initialized features.tsv db.sqlite Clone the repository, install the packages for Covidscope and run the web portal code","title":"Reimplementation one-by-one steps"},{"location":"#quickstart-guide-after-data-imported-to-mongodb","text":"$ git clone https://github.com/hiyin/covid19_cell_atlas_portal.git $ cd covid19_cell_atlas_portal # create virtual environment $ python3.9 -m pip install --upgrade pip $ python3.9 -m venv venv # this installs the venv folder in the current directory $ source venv/bin/activate $ pip install -r requirements.txt # deactivate the environment and reactivate it for a fresh start $ deactivate $ source venv/bin/activate # initialize database download it and put it in flask_resources/ directory in yor $HOME mv db.sqlite $HOME/flask_resources/ mv features.tsv $HOME/flask_resources/ # set environment $ export FLASK_ENV=development $ export FLASK_APP=manage.py # launch $ flask run You will have local version of Covidscope running at 127.0.0.1:5000 by default. You shall be able to have your own version of Covidscope running with your custom files if you could modify to the data format same as the example files we used here for demonstration!","title":"Quickstart guide (after data imported to MongoDB)"},{"location":"#prepare-your-data-for-scope-reimplementation","text":"We assume that you start with the two common files after you have collected your single-cell RNA-seq data i.e. meta data, and a count matrix folder in 10X single-cell sequencing format. Below is a example pipeline to help you to process the files. We asssume that you have a metadata file following our structures (if not please edit according to our example metadata) Example metadata: metadata Example 10X format matrix folder files: barcodes.tsv.gz genes.tsv.gz matrix.mtx.gz Download them and save as into a new directory named hoehn_2021/ meta <- read.csv(\"importdata_metadata.csv\") # Prepare matrix db collection source hoehn <- Read10X(\"hoehn_2021/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(hoehn) rownames(meta) <- meta$id metadata_frame <- srt_obj@meta.data univ_meta <- cbind(metadata_frame, meta) srt_obj <- AddMetaData(srt_obj, univ_meta) # if the user didn't have pca srt_obj <- NormalizeData(srt_obj) srt_obj <- FindVariableFeatures(srt_obj, selection.method = \"vst\", nfeatures = 2000) all.genes <- rownames(srt_obj) srt_obj <- ScaleData(srt_obj, features=all.genes) srt_obj <- RunPCA(srt_obj, features = VariableFeatures(object = srt_obj)) srt_obj <- RunUMAP(srt_obj, dims = 1:40) # Prepare UMAP file for database import umap_coord <- dplyr::as_tibble(data.frame(srt_obj@reductions$umap@cell.embeddings ), rownames = \"id\") colnames(umap_coord) <- c(\"id\", \"UMAP1\",\"UMAP2\") write.csv(umap_coord, file=\"importdata_umap.csv\", row.names = FALSE) # Prepare matrix file for database import # input: a sparse matrix with named rows and columns (dimnames) # returns: a data frame representing triplets (r, c, x) suitable for writing to a CSV file sparse2triples <- function(m) { SM = summary(m) D1 = m@Dimnames[[1]][SM[,1]] D2 = m@Dimnames[[2]][SM[,2]] data.frame(row=D1, col=D2, x=m@x) } # get matrix file towrite_matrix <- sparse2triples(srt_obj[[\"RNA\"]]@counts) colnames(towrite_matrix) <- c(\"gene_name\", \"barcode\", \"expression\") # write matrix data write.csv(towrite_matrix, file=\"importdata_matrix.csv\", row.names=FALSE) For a quick reproduction of Covidscope local version, you could download our prepared and processed files and directly import them into the MongoDB: 1. matrix 2. metadata 3. umap","title":"Prepare your data for Scope+ reimplementation"},{"location":"#how-to-use-covidscope-data","text":"For any user would like to use Covidscope data, downloaded from https://covidsc.d24h.hk/data, Covidscope provide the data in 10X format therefore you can read the three .gz files using Seurat package's function Read10X . An example is given below data <- Read10X(\"lee_2020/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(data)","title":"How to use Covidscope data"}]}