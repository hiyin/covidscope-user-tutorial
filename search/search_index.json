{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Covidscope reimplementation theme: name: readthedocs highlightjs: true hljs_languages: - yaml - rust The reimplementation process is straightforward. You only need three separate files to start. Input file: Metadata Count matrix UMAP coordinates Example input files are provided for your reference. Input files needed to be in .csv format. We assume that users have analyzed their data in one of the most popular software Seurat in R. You can output your three input files from your Seurat object by: * Metadata: your own metadata file in .csv format i.e. meta.csv * Count matrix: # https://stackoverflow.com/questions/4558277/write-a-sparse-matrix-to-a-csv-in-r colnames(dense_matrix) <- c(\u201cgene_name\u201d, \u201cbarcode\u201d,\u201dexpression\u201d) write.csv(dense_matrix, file=\u201dmatrix.csv\u201d, row.names=FALSE) UMAP: If you have run the UMAP step, otherwise please refer to Seurat UMAP method and run it first. umap_coord <- dplyr::as_tibble(data.frame(seurat_object@reductions$umap@cell.embeddings), rownames = \"id\") colnames(umap_coord) <- c(\u201did\u201c, \u201cUMAP1\u201d,\u201dUMAP2\u201d) write.csv(umap_coord, file=\u201dumap.csv\u201d, row.names=FALSE) Input file content: **File name** **Collection name** **Columns** metadata.csv single_cell_meta_v4 [\"id\", \"meta_age_category\", \"meta_sample_id2\",\"meta_patient_id\", \"meta_dataset\", \"level2\", \"meta_severity\", \"meta_days_from_onset_of_symptoms\", \"meta_outcome\", \"meta_gender\", \"Country\"] matrix.csv matrix [\"barcode\", \"gene_name\",\"expression\"] umap.csv umap [\"UMAP1\",\"UMAP2\", \"id\"] Database collection **Column name** **Value format** **Description** **Example** Collection schema: **single_cell_meta_v4** id String Cell barcode (unique) meta_patient_id String Patient identifier meta_sample_id2 String Sample identifier (one patient may have multiple samples) Country String Country origin of the dataset meta_age_category String Age category in intervals e.g. \u201c18-30\u201d level2 String Cell type predictions meta_severity String The severity of the symptoms regarding patient meta_dataset String Dataset origin meta_days_from_onset_of_symptoms Number Days from the onset of symptoms meta_gender String Gender i.e. \u201cfemale\u201d or \u201cmale\u201d meta_outcome String Health outcome i.e. \u201cdiseased\u201d, \u201cdischarged\u201d etc. Collection schema: **umap** id String Cell barcode (unique) UMAP1 String X-coordinate of the cell UMAP2 String Y-coordiante of the cell Collection schema: **matrix** barcode String Cell barcode (unique) gene_name String Name of the gene expressed in the cell e.g. CD19 expression Number Dependencies: MongoDB installed Python3.9 installed MongoDB Compass installed (optional, for visual operation of the database) sqlite installed Reimplementation steps: Install the system dependencies listed above, MongoDB, Python, MongoDB Compass (optional) and sqlite. Create a database in MongoDB named cov19atlas_new, and create three collections namely under the database single_cell_meta_v4 umap matrix Import the three datasets into MongoDB using MongoDB Compass, make sure all data field during import needs to be in STRING format.: single_cell_meta_v4 (meta.csv) umap (umap.csv) and matrix (matrix.csv). Download Covidscope web portal resources below into flask_resources directory under your $HOME, without them the web portal can't be initialized features.tsv db.sqlite Clone the repository, install the packages for Covidscope and run the web portal code Activate the virtual environment if you created $ git clone https://github.com/hiyin/covid19_cell_atlas_portal.git $ cd covid19_cell_atlas_portal # create virtual environment $ python3.9 -m pip install --upgrade pip $ python3.9 -m venv venv # this installs the venv folder in the current directory $ source venv/bin/activate $ pip install -r requirements.txt # deactivate the environment and reactivate it for a fresh start $ deactivate $ source venv/bin/activate # initialize database download it and put it in flask_resources/ directory in yor $HOME mv db.sqlite $HOME/flask_resources/ mv features.tsv $HOME/flask_resources/ # set environment $ export FLASK_ENV=development $ export FLASK_APP=manage.py # launch $ flask run You will have local version of Covidscope running at 127.0.0.1:5000 by default. Quickstart example We assume that you start with the two common files after you have collected your single-cell RNA-seq data i.e. meta data, and a count matrix folder in 10X single-cell sequencing format. Below is a example pipeline to help you to process the files. We asssume that you have a metadata file following our structures (if not please edit according to our example metadata) Example metadata: metadata Example 10X format matrix folder files: barcodes.tsv.gz genes.tsv.gz matrix.mtx.gz Download them and save as into a new directory named hoehn_2021/ meta <- read.csv(\"importdata_metadata.csv\") # Prepare matrix db collection source hoehn <- Read10X(\"hoehn_2021/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(hoehn) rownames(meta) <- meta$id metadata_frame <- srt_obj@meta.data univ_meta <- cbind(metadata_frame, meta) srt_obj <- AddMetaData(srt_obj, univ_meta) # if the user didn't have pca srt_obj <- NormalizeData(srt_obj) srt_obj <- FindVariableFeatures(srt_obj, selection.method = \"vst\", nfeatures = 2000) all.genes <- rownames(srt_obj) srt_obj <- ScaleData(srt_obj, features=all.genes) srt_obj <- RunPCA(srt_obj, features = VariableFeatures(object = srt_obj)) srt_obj <- RunUMAP(srt_obj, dims = 1:40) # UMAP file umap_coord <- dplyr::as_tibble(data.frame(srt_obj@reductions$umap@cell.embeddings ), rownames = \"id\") colnames(umap_coord) <- c(\"id\", \"UMAP1\",\"UMAP2\") write.csv(umap_coord, file=\"importdata_umap.csv\", row.names = FALSE) For a quickstart, you could download our prepared and processed files and directly import them into the MongoDB: 1. matrix 2. metadata 3. umap You shall be able to have your own version of Covidscope running with your custom files if you could modify to the data format same as the example files we used here for demonstration!","title":"Covidscope reimplementation"},{"location":"#covidscope-reimplementation","text":"theme: name: readthedocs highlightjs: true hljs_languages: - yaml - rust The reimplementation process is straightforward. You only need three separate files to start.","title":"Covidscope reimplementation"},{"location":"#input-file","text":"Metadata Count matrix UMAP coordinates Example input files are provided for your reference. Input files needed to be in .csv format. We assume that users have analyzed their data in one of the most popular software Seurat in R. You can output your three input files from your Seurat object by: * Metadata: your own metadata file in .csv format i.e. meta.csv * Count matrix: # https://stackoverflow.com/questions/4558277/write-a-sparse-matrix-to-a-csv-in-r colnames(dense_matrix) <- c(\u201cgene_name\u201d, \u201cbarcode\u201d,\u201dexpression\u201d) write.csv(dense_matrix, file=\u201dmatrix.csv\u201d, row.names=FALSE) UMAP: If you have run the UMAP step, otherwise please refer to Seurat UMAP method and run it first. umap_coord <- dplyr::as_tibble(data.frame(seurat_object@reductions$umap@cell.embeddings), rownames = \"id\") colnames(umap_coord) <- c(\u201did\u201c, \u201cUMAP1\u201d,\u201dUMAP2\u201d) write.csv(umap_coord, file=\u201dumap.csv\u201d, row.names=FALSE)","title":"Input file:"},{"location":"#input-file-content","text":"**File name** **Collection name** **Columns** metadata.csv single_cell_meta_v4 [\"id\", \"meta_age_category\", \"meta_sample_id2\",\"meta_patient_id\", \"meta_dataset\", \"level2\", \"meta_severity\", \"meta_days_from_onset_of_symptoms\", \"meta_outcome\", \"meta_gender\", \"Country\"] matrix.csv matrix [\"barcode\", \"gene_name\",\"expression\"] umap.csv umap [\"UMAP1\",\"UMAP2\", \"id\"]","title":"Input file content:"},{"location":"#database-collection","text":"**Column name** **Value format** **Description** **Example** Collection schema: **single_cell_meta_v4** id String Cell barcode (unique) meta_patient_id String Patient identifier meta_sample_id2 String Sample identifier (one patient may have multiple samples) Country String Country origin of the dataset meta_age_category String Age category in intervals e.g. \u201c18-30\u201d level2 String Cell type predictions meta_severity String The severity of the symptoms regarding patient meta_dataset String Dataset origin meta_days_from_onset_of_symptoms Number Days from the onset of symptoms meta_gender String Gender i.e. \u201cfemale\u201d or \u201cmale\u201d meta_outcome String Health outcome i.e. \u201cdiseased\u201d, \u201cdischarged\u201d etc. Collection schema: **umap** id String Cell barcode (unique) UMAP1 String X-coordinate of the cell UMAP2 String Y-coordiante of the cell Collection schema: **matrix** barcode String Cell barcode (unique) gene_name String Name of the gene expressed in the cell e.g. CD19 expression Number","title":"Database collection"},{"location":"#dependencies","text":"MongoDB installed Python3.9 installed MongoDB Compass installed (optional, for visual operation of the database) sqlite installed","title":"Dependencies:"},{"location":"#reimplementation-steps","text":"Install the system dependencies listed above, MongoDB, Python, MongoDB Compass (optional) and sqlite. Create a database in MongoDB named cov19atlas_new, and create three collections namely under the database single_cell_meta_v4 umap matrix Import the three datasets into MongoDB using MongoDB Compass, make sure all data field during import needs to be in STRING format.: single_cell_meta_v4 (meta.csv) umap (umap.csv) and matrix (matrix.csv). Download Covidscope web portal resources below into flask_resources directory under your $HOME, without them the web portal can't be initialized features.tsv db.sqlite Clone the repository, install the packages for Covidscope and run the web portal code","title":"Reimplementation steps:"},{"location":"#activate-the-virtual-environment-if-you-created","text":"$ git clone https://github.com/hiyin/covid19_cell_atlas_portal.git $ cd covid19_cell_atlas_portal # create virtual environment $ python3.9 -m pip install --upgrade pip $ python3.9 -m venv venv # this installs the venv folder in the current directory $ source venv/bin/activate $ pip install -r requirements.txt # deactivate the environment and reactivate it for a fresh start $ deactivate $ source venv/bin/activate # initialize database download it and put it in flask_resources/ directory in yor $HOME mv db.sqlite $HOME/flask_resources/ mv features.tsv $HOME/flask_resources/ # set environment $ export FLASK_ENV=development $ export FLASK_APP=manage.py # launch $ flask run You will have local version of Covidscope running at 127.0.0.1:5000 by default.","title":"Activate the virtual environment if you created"},{"location":"#quickstart-example","text":"We assume that you start with the two common files after you have collected your single-cell RNA-seq data i.e. meta data, and a count matrix folder in 10X single-cell sequencing format. Below is a example pipeline to help you to process the files. We asssume that you have a metadata file following our structures (if not please edit according to our example metadata) Example metadata: metadata Example 10X format matrix folder files: barcodes.tsv.gz genes.tsv.gz matrix.mtx.gz Download them and save as into a new directory named hoehn_2021/ meta <- read.csv(\"importdata_metadata.csv\") # Prepare matrix db collection source hoehn <- Read10X(\"hoehn_2021/\", gene.column = 1) # default tsv.gz files (downloaded from Covidscope) srt_obj <- CreateSeuratObject(hoehn) rownames(meta) <- meta$id metadata_frame <- srt_obj@meta.data univ_meta <- cbind(metadata_frame, meta) srt_obj <- AddMetaData(srt_obj, univ_meta) # if the user didn't have pca srt_obj <- NormalizeData(srt_obj) srt_obj <- FindVariableFeatures(srt_obj, selection.method = \"vst\", nfeatures = 2000) all.genes <- rownames(srt_obj) srt_obj <- ScaleData(srt_obj, features=all.genes) srt_obj <- RunPCA(srt_obj, features = VariableFeatures(object = srt_obj)) srt_obj <- RunUMAP(srt_obj, dims = 1:40) # UMAP file umap_coord <- dplyr::as_tibble(data.frame(srt_obj@reductions$umap@cell.embeddings ), rownames = \"id\") colnames(umap_coord) <- c(\"id\", \"UMAP1\",\"UMAP2\") write.csv(umap_coord, file=\"importdata_umap.csv\", row.names = FALSE) For a quickstart, you could download our prepared and processed files and directly import them into the MongoDB: 1. matrix 2. metadata 3. umap You shall be able to have your own version of Covidscope running with your custom files if you could modify to the data format same as the example files we used here for demonstration!","title":"Quickstart example"}]}